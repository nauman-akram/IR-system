{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSDS19041_A1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nauman-akram/textfilesACL/blob/master/IR-System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUEK1HyypfS6",
        "colab_type": "code",
        "outputId": "7b9419c4-ec20-41a4-e61d-8bb40d2057fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpxiIdImfl3U",
        "colab_type": "code",
        "outputId": "c4c88d2c-20d9-4e13-d523-82e6e4d93e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UtpICdnfnWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip 'ACL txt.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNQtXdlBgCdB",
        "colab_type": "code",
        "outputId": "97e681b1-cdd0-4b4f-85f8-6d5d69bf8ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /gdrive/My Drive/Classroom/Information Retrieval & Text Mining Fall 2019/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Classroom/Information Retrieval & Text Mining Fall 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fKVPHXJp-pG",
        "colab_type": "code",
        "outputId": "1ac69ca4-ebcd-46ac-dc7d-62286427a242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ACL_txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Classroom/Information Retrieval & Text Mining Fall 2019/ACL_txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbUnwQfKjaWE",
        "colab_type": "code",
        "outputId": "8caf5a85-1cb1-4fd3-a782-5c70c8fe83b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "directory = os.getcwd()\n",
        "directory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/Classroom/Information Retrieval & Text Mining Fall 2019/ACL_txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3l-nFfF7JvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordList(doc):\n",
        "    fileHandler= open(doc,encoding='Latin-1')\n",
        "    content = fileHandler.read()\n",
        "    fileHandler.close()\n",
        "    return content.split()\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G73nYVDr8UIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import utils\n",
        "import gensim.parsing.preprocessing as gsp\n",
        "\n",
        "filters = [\n",
        "           gsp.strip_punctuation,\n",
        "           gsp.strip_multiple_whitespaces,\n",
        "           gsp.remove_stopwords,\n",
        "          ]\n",
        "\n",
        "def removePunc(wordlist):\n",
        "    req_list = []\n",
        "    for word in wordlist:\n",
        "        word = word.lower()\n",
        "        for fltr in filters:\n",
        "            word = fltr(word)\n",
        "        if len(word) != 0:\n",
        "            req_list.append(word)\n",
        "    return req_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFiuqv1V8YiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def termFrequencyInDoc(words_List):\n",
        "    doc_dict = dict()\n",
        "    for word in words_List:\n",
        "        if word in doc_dict:\n",
        "            doc_dict[word] += 1\n",
        "        else:\n",
        "            doc_dict[word] = 1\n",
        "    return doc_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UooKmYE382Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordDocFreq(dictList):\n",
        "    docFreq = dict()\n",
        "    for docDict in dictList:\n",
        "        for word in docDict.keys():\n",
        "            if word in docFreq:\n",
        "                docFreq[word] += 1\n",
        "            else:\n",
        "                docFreq[word] = 1\n",
        "    return docFreq\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LgD-iSwYg3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def inverseDocFreq(dictList_wdf,M):    \n",
        "    \n",
        "    idf_corpus = {}\n",
        "    for word in dictList_wdf.keys():\n",
        "        idf_corpus[word] = np.log2((M+1) / dictList_wdf[word]) #log_2 ((M+1)/k)\n",
        "    \n",
        "    return idf_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBYOpS8jY-a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf(docsList):\n",
        "    M = len(docsList)\n",
        "    tf_dictList = []\n",
        "    x=0\n",
        "    for doc_path in docsList:\n",
        "        x += 1\n",
        "        words_List = wordList(doc_path) #calling first function to tokenize words\n",
        "        clean_words_List = removePunc(words_List) #cleaning words form punc,\\n,stopwords, get in lower value\n",
        "        doc_dict = termFrequencyInDoc(clean_words_List) #calculate termfreqs in each document\n",
        "        tf_dictList.append(doc_dict) #make list of dictionaries; every dictionary contain term freqs of words in document ##TF\n",
        "        if x % 500 == 0:\n",
        "            print(\"In loop\",x,\"files have been processed!\")   \n",
        "\n",
        "    wdf = wordDocFreq(tf_dictList)\n",
        "    print(\"word-document frequency is calculated for whole vocab!\")\n",
        "    idfs = inverseDocFreq(wdf,M)\n",
        "\n",
        "    print(\"Inv w-d frequency is calculated for whole vocab!\")\n",
        "    #print(idfs)\n",
        "    #calulate tf*idfs of each word in each document make ditionary for every document!\n",
        "    tf_idfs = [] #list of dictionaries containing tf-ids\n",
        "    for docDict in tf_dictList:\n",
        "        dict_doc_tfidf = dict()\n",
        "        for word in docDict.keys():\n",
        "            dict_doc_tfidf[word] = docDict[word] * idfs[word]\n",
        "        tf_idfs.append(dict_doc_tfidf)\n",
        "    \n",
        "    vocab = idfs.keys()\n",
        "\n",
        "    return tf_dictList, tf_idfs, vocab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kBz7vZ3ozVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dictionaries(docsList,dictList,tf_idfs):\n",
        "    names = []\n",
        "    for doc_path in docsList:\n",
        "        names.append(os.path.basename(doc_path))\n",
        "    \n",
        "    tf_idf_docs_dict = dict(zip(names,tf_idfs))\n",
        "    tf_docs_dict = dict(zip(names,dictList))\n",
        "    return  tf_docs_dict, tf_idf_docs_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMR9Pf9Rrrup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VectorSpaceModel (query,tf_idf_docs_dict, vocab):   \n",
        "    query_vocab = [] \n",
        "    for word in query.split():\n",
        "        if word not in query_vocab:\n",
        "            query_vocab.append(word.lower())\n",
        "    \n",
        "    query_wc = {} # a dictionary to store count of a word in the query (i.e x_i according to lecture slides terminology)\n",
        "    #print(query_vocab)\n",
        "    query = query.lower()\n",
        "    for word in query_vocab:\n",
        "        query_wc[word] = query.split().count(word)\n",
        "    #print(query_wc)\n",
        "    relevance_scores = {} \n",
        "\n",
        "    for doc_name in tf_idf_docs_dict.keys():\n",
        "        score = 0 \n",
        "        for word in query_vocab:\n",
        "            if word in tf_idf_docs_dict[doc_name].keys():\n",
        "                score += query_wc[word] * tf_idf_docs_dict[doc_name][word]\n",
        "            else: \n",
        "                continue\n",
        "        relevance_scores[doc_name] = score\n",
        "    \n",
        "   \n",
        "    top_5 = sorted(relevance_scores, key=relevance_scores.get, reverse=True)[:5]\n",
        "    print(\"Document Relevancy Scores\\n\")\n",
        "    print(query,\"belongs to: \")\n",
        "    for i in top_5:\n",
        "        print(\"file\",i,\" , with score: \",np.round(relevance_scores[i],2) )\n",
        "\n",
        "    return relevance_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mljgH-GB0boG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_files = []\n",
        "for files in os.walk(directory):\n",
        "  for file in files[-1]:\n",
        "    list_files.append(os.path.join(directory,file))\n",
        "\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eVW2HcY0fCZ",
        "colab_type": "code",
        "outputId": "9212b57d-9457-441a-f161-cbacfa4ed0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "tf_dictList, tf_idfs, vocab = tfidf(list_files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In loop 500 files have been processed!\n",
            "In loop 1000 files have been processed!\n",
            "In loop 1500 files have been processed!\n",
            "In loop 2000 files have been processed!\n",
            "In loop 2500 files have been processed!\n",
            "In loop 3000 files have been processed!\n",
            "In loop 3500 files have been processed!\n",
            "In loop 4000 files have been processed!\n",
            "In loop 4500 files have been processed!\n",
            "In loop 5000 files have been processed!\n",
            "In loop 5500 files have been processed!\n",
            "In loop 6000 files have been processed!\n",
            "In loop 6500 files have been processed!\n",
            "In loop 7000 files have been processed!\n",
            "In loop 7500 files have been processed!\n",
            "In loop 8000 files have been processed!\n",
            "In loop 8500 files have been processed!\n",
            "In loop 9000 files have been processed!\n",
            "In loop 9500 files have been processed!\n",
            "In loop 10000 files have been processed!\n",
            "In loop 10500 files have been processed!\n",
            "In loop 11000 files have been processed!\n",
            "In loop 11500 files have been processed!\n",
            "In loop 12000 files have been processed!\n",
            "In loop 12500 files have been processed!\n",
            "In loop 13000 files have been processed!\n",
            "In loop 13500 files have been processed!\n",
            "In loop 14000 files have been processed!\n",
            "In loop 14500 files have been processed!\n",
            "In loop 15000 files have been processed!\n",
            "In loop 15500 files have been processed!\n",
            "In loop 16000 files have been processed!\n",
            "In loop 16500 files have been processed!\n",
            "In loop 17000 files have been processed!\n",
            "In loop 17500 files have been processed!\n",
            "In loop 18000 files have been processed!\n",
            "In loop 18500 files have been processed!\n",
            "In loop 19000 files have been processed!\n",
            "In loop 19500 files have been processed!\n",
            "In loop 20000 files have been processed!\n",
            "In loop 20500 files have been processed!\n",
            "In loop 21000 files have been processed!\n",
            "In loop 21500 files have been processed!\n",
            "word-document frequency is calculated for whole vocab!\n",
            "Inv w-d frequency is calculated for whole vocab!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxiT_Um10Ila",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_docs_dict, tf_idf_docs_dict = get_dictionaries(list_files,tf_dictList,tf_idfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA3e3Itp0KoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query1 = \"Text Mining\"\n",
        "query2 = \"LDA\"\n",
        "query3 = \"topic modelling\"\n",
        "query4 = \"Natural language Processing\"\n",
        "query5 = \"generative Models\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHh0tu3Y4Jo9",
        "colab_type": "code",
        "outputId": "06193169-604d-498f-ffca-03631ac771cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rel_score_all = VectorSpaceModel(query1,tf_idf_docs_dict,vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document Relevancy Scores\n",
            "\n",
            "text mining belongs to: \n",
            "file D09-1162.pdf.txt  , with score:  163.19\n",
            "file P06-1062.pdf.txt  , with score:  162.88\n",
            "file P12-1062.pdf.txt  , with score:  123.7\n",
            "file W09-2609.pdf.txt  , with score:  120.4\n",
            "file P09-1098.pdf.txt  , with score:  111.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1j1Zfa9Bqtf",
        "colab_type": "code",
        "outputId": "cd85e947-7cc1-4540-a3b2-d8dbfdbba38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSavlSJi4O8y",
        "colab_type": "code",
        "outputId": "c428c494-f846-4764-c8dc-562a3f408853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rel_score_all = VectorSpaceModel(query2,tf_idf_docs_dict,vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document Relevancy Scores\n",
            "\n",
            "lda belongs to: \n",
            "file J14-2003.pdf.txt  , with score:  381.57\n",
            "file D09-1026.pdf.txt  , with score:  352.22\n",
            "file D11-1050.pdf.txt  , with score:  342.44\n",
            "file N10-1070.pdf.txt  , with score:  313.09\n",
            "file P10-1117.pdf.txt  , with score:  298.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO1H0ggF5bJo",
        "colab_type": "code",
        "outputId": "b56ba7ba-e7a0-4613-9e4a-054c01d077dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rel_score_all = VectorSpaceModel(query3,tf_idf_docs_dict,vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document Relevancy Scores\n",
            "\n",
            "topic modelling belongs to: \n",
            "file J14-2003.pdf.txt  , with score:  380.15\n",
            "file P12-1079.pdf.txt  , with score:  337.71\n",
            "file Q15-1004.pdf.txt  , with score:  302.64\n",
            "file N15-1074.pdf.txt  , with score:  300.8\n",
            "file W10-4104.pdf.txt  , with score:  280.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmjpMZhQ5dvg",
        "colab_type": "code",
        "outputId": "f2864b8d-6999-4e2f-884d-01a27d66b43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rel_score_all  = VectorSpaceModel(query4,tf_idf_docs_dict,vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document Relevancy Scores\n",
            "\n",
            "natural language processing belongs to: \n",
            "file W11-0100.pdf.txt  , with score:  154.24\n",
            "file J14-1005.pdf.txt  , with score:  89.61\n",
            "file J87-1020.pdf.txt  , with score:  86.23\n",
            "file W14-55.x.pdf.txt  , with score:  61.91\n",
            "file J86-2001.pdf.txt  , with score:  55.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWLnRQZ25gTe",
        "colab_type": "code",
        "outputId": "09dfb768-0ede-4549-b6a3-fb6d4ef4fd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rel_score_all = VectorSpaceModel(query5,tf_idf_docs_dict,vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document Relevancy Scores\n",
            "\n",
            "generative models belongs to: \n",
            "file W06-1668.pdf.txt  , with score:  187.97\n",
            "file W11-0100.pdf.txt  , with score:  176.97\n",
            "file J03-4003.pdf.txt  , with score:  150.44\n",
            "file D09-1111.pdf.txt  , with score:  133.06\n",
            "file D09-1058.pdf.txt  , with score:  132.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aUe8peT5h7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4YXV5CCHchP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}